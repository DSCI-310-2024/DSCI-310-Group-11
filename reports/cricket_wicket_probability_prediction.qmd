---
title: 'DSCI 310 Group 11 Project: Predicting Probability of Wicket on a Delivery in Cricket'
jupyter: python3
---


Alex Lin

Jackson Siemens

Shruti Vijaykumar Seetharam

Hanlin Zhao


## Abstract

Our project aims to predict the probability of a wicket on a delivery in Cricket. We are going to look at ball-by-ball factors that could potentially affect this probability and see how the wicket probability changes with game conditions. Forecasting methods for cricket use complex regression models as discussed by Asif & McHale (2016), which is why we decided against predicting win probability, a common prediction model used for sports

## Introduction

Cricket is a bat and ball sport involving two teams of eleven players each. Originating in the 16th century, Cricket today is commonly played in three formats: Tests, One Day Internationals and T20 Internationals. Our analysis will be specifically focusing on T20 International games and looking at the conditions of those games to analyze our prediction probability. In a T20 game, one team will bat first and set a target number of runs in 20 overs or until 10 wickets are lost. The other team will bat second, and to win the game, they must exceed the target set by the second team in 20 overs or less. Each of the 11 players in the team will need to bat as more wickets are lost, but some bat more often than others, given all wickets are not always lost. Only some players are bowlers. There are multiple different ways of getting a wicket, and these can be affected by the following factors:

1. Bowler: The skill of a bowler can affect the probability
2. Batter: Similarly, the skill of a batter can affect the probability
3. Inning: Determines which team is batting and bowling
4. Over: An over consists of 6 deliveries thrown by the bowler from one end of the pitch to the batter on the other end. The over can determine how much risk a batter is willing to take with his next ball.
5. Ball in the over: The specific delivery in the over. Batters are more likely to take risks towards the end of an over compared to the beginning.
6. Runs scored till now: Looks at the amount of runs scored in the inning up until the current ball. Fewer runs scored may mean the batter is more likely to take risks in order to get more.
7. Powerplay: A powerplay is when there are fielding restrictions placed on the bowling team, making it harder for them to get a wicket. 

We will be looking at the above factors along with some others to judge what factors may be best for our model in the Exploratory Data Analysis section. We will be reading our data in json files from the [Cricsheet](https://cricsheet.org/downloads/) website, and converting it to our desired `csv` format using the scripts in the `cricsheet_json_parsing.ipynb` file which can be found in the `src` folder. 

```{python}
#| results: hide
import numpy as np
import pandas as pd
import altair as alt
import matplotlib.pyplot as plt
import sklearn.metrics as metrics
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import make_pipeline
from sklearn.compose import make_column_transformer

alt.data_transformers.enable("vegafusion")
alt.renderers.enable('jupyterlab')
alt.renderers.enable('mimetype')
```

## Methods

Firstly, we will perform some exploratory data analysis on the training data to get a better understanding of the dataset and what relationships there are with our target variable.

### Exploratory Data Analysis

```{python}
#| scrolled: true
data = pd.read_csv("data/cricket_test.csv")
data = data.drop(columns = ["Unnamed: 0"])
data.head().style.set_caption("Table 1: Overview of full dataset").set_table_styles([{
     'selector': 'caption',
     'props': 'caption-side: bottom; font-size:1.25em;'
 }], overwrite=False)
```

```{python}
X = data.drop(columns = ['wicket'])
y = data['wicket']

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)
train_data = pd.concat([X_train, y_train], axis = 1)
```

```{python}
train_data.info()
```

```{python}
train_data.describe().style.set_caption("Table 2: Summary of Numeric Variables").set_table_styles([{
     'selector': 'caption',
     'props': 'caption-side: bottom; font-size:1.25em;'
 }], overwrite=False)
```

The dataset contains 28 columns and 510652 observations related to cricket. The ratio of quantitative to categorical (ordinal and nominal) data is approximately 50:50. Note that the columns **player_out, player_out_id, fielder_name, fielders_id, and wicket_type** show a significant amount of missing values. Player_out and player_out_id may be missing due to inapplicability (e.g., no one is out), which results in fielder_name, fielder_id, and wicket_type being invalid in these observations. Thus, these missing data are likely classified as **missing at random(MAR)**. Given the complexity of imputing these values, they are unlikely to be included in our further analysis.

Note that, among the 28 columns, there were few attributes generated based on existing columns, and they are "over_ball", "inning", "runs_cumulative", and "powerplay". Although they are all integers, it is important to note that, only "overball" and "runs_cumulative" are quantitative, whereas "inning" and "powerplay" are categorical. Detailed calculations of these attributes are in the `cricsheet-json-parsing.ipynb` file. 

```{python}
def vis_bar(x_input, width, height):
    return alt.Chart(train_data).mark_bar().encode(
        x = x_input,
        y = "count()"
    ).properties(
        width = width, 
        height = height
    )

over = vis_bar("over", 150, 150)
wides = vis_bar("wides", 150, 150)
noballs = vis_bar("noballs", 150, 150)
legbyes = vis_bar("legbyes", 150, 150)
byes = vis_bar("byes", 150, 150)
wicket = vis_bar("wicket", 150, 150)
run_batter = vis_bar("runs_batter", 150, 150)
run_extras = vis_bar("runs_extras", 150, 150)
run_total = vis_bar("runs_total", 150, 150)
over_ball = vis_bar("over_ball", 150, 150)
runs_cumulative = vis_bar("runs_cumulative", 150, 150)

title_1_a = alt.Chart(
    {"values": [{"text": "Figure 1.1: Distribution of Variables"}]}
).mark_text(size=20).encode(
    text="text:N"
)

v1 = alt.hconcat(over, wides, noballs)
v2 = alt.hconcat(legbyes, byes, wicket)
v3 = alt.hconcat(run_batter, run_extras, run_total)
v4 = alt.hconcat(over_ball, runs_cumulative)
chart1 = alt.vconcat(title_1_a, v1, v2, v3, v4)
chart1.save('images/chart1.png')
```

![Figure 1.1](images/chart1.png)

```{python}
season = vis_bar("season", 500, 150)
team = vis_bar("team", 900, 150)
inning = vis_bar("inning:N", 150, 150)
powerplay = vis_bar("powerplay:N", 150, 150)

title_1_b = alt.Chart(
    {"values": [{"text": "Figure 1.2: Distribution of Variables"}]}
).mark_text(size=20).encode(
    text="text:N"
)

h_1 = alt.hconcat(inning, powerplay)
chart2 = alt.vconcat(title_1_b, season, team, h_1)
chart2.save('images/chart2.png')
```

![Figure 1.2](images/chart2.png)

Figure 1.1 and Figure 1.2 look at the distribution of our variables.

```{python}
pd.concat([train_data["batter"].value_counts().reset_index().head(5), 
           train_data["batter"].value_counts().reset_index().tail(5)]).style.set_caption(
    "Table 3.1: Batter Summary Count").set_table_styles([{
     'selector': 'caption',
     'props': 'caption-side: bottom; font-size:1.25em;'
 }], overwrite=False)
```

```{python}
pd.concat([train_data["bowler"].value_counts().reset_index().head(5), 
           train_data["bowler"].value_counts().reset_index().tail(5)]).style.set_caption(
    "Table 3.2: Bowler Summary Count").set_table_styles([{
     'selector': 'caption',
     'props': 'caption-side: bottom; font-size:1.25em;'
 }], overwrite=False)
```

```{python}
pd.concat([train_data["non_striker"].value_counts().reset_index().head(5),
           train_data["non_striker"].value_counts().reset_index().tail(5)]).style.set_caption(
    "Table 3.3: Non-Striker Summary Count").set_table_styles([{
     'selector': 'caption',
     'props': 'caption-side: bottom; font-size:1.25em;'
 }], overwrite=False)
```

Please note that the analysis excludes all columns related to "ID" as they are primarily for identification purposes and are unlikely to show significant patterns. It is observed that none of the quantitative attributes follow a normal distribution; most are right-skewed distributions. An interesting finding is noted in the attributes "over", where the frequency **steadily** decreases with increasing values, suggesting further analysis. Concerning ordinal attributes, we have a significantly higher amount of data from seasons that happened in recent years than in the past. Lastly, regarding nominal attributes, we are seeing an uneven distribution appearance of players(batter, bowler, and non-striker) in this dataset, by using non-striker as an example, some players such as V Kohli appear around 2100 times in this dataset, where other players such as F Bangur only appeared once.  Due to such a large number of batters and bowlers in the dataset, we will not be using it in our analysis. To use these attributes, we will also need to create summary statistics for each batters and bowlers, as explained by Dinsdale (2023) which is out of the scope of our project.

In terms of "team", there appear to be more teams from "New Zealand," "South Africa," "India," "West India," "Pakistan," "Bangladesh," "Sri Lanka"  "Australia," and "England" than teams from other countries/regions. The attribute"inning" doesn't seem to have a significant difference across the two conditions, however, for "powerplay," the number of occurrences in condition "0" is approximately twice as high as in condition "1."

In general, **none of the attributes in our dataset form a normal distribution**, with samples unevenly distributed across categorical attributes. It is important to remember this when training, testing, and interpreting the model, and to appropriately acknowledge this as a potential limitation. 

### Multivariate Analysis - Correlation Analysis

```{python}
corr_data = train_data[["over", "wides", "noballs", "legbyes", "byes", "runs_batter", "runs_extras", "runs_total", "over_ball", "runs_cumulative", "wicket"]]
corr_df = corr_data.corr()
corr_df.style.set_caption("Table 4: Correlation Analysis").set_table_styles([{
     'selector': 'caption',
     'props': 'caption-side: bottom; font-size:1.25em;'
 }], overwrite=False)
```

```{python}
corr_ = corr_df.stack()
corr_ = corr_.reset_index()
corr_.columns = ['row', 'column', 'corr']
corr_

chart3 = alt.Chart(corr_).mark_rect().encode(
    x = 'column',
    y = 'row',
    color = 'corr:Q',
    tooltip = 'corr:Q'
).properties(
    width = 400,
    height = 400,
    title = "Figure 2: Correlation Matrix"
)

chart3.save('images/chart3.png')
```

![Figure 3](images/chart3.png)

```{python}
corr_table = corr_[corr_["row"] != corr_["column"]]
(corr_table.sort_values("corr", ascending = False).head(15)).style.set_caption("Table 5: Correlation Coefficients for top 15 most correlated variables").set_table_styles([{
     'selector': 'caption',
     'props': 'caption-side: bottom; font-size:1.25em;'
 }], overwrite=False)
```

Among the quantitative attributes, 5 pairs of relationship are above the threshold of weak correlation(**|r| > 0.3**), and they are: 

1. **batter_total & run_total(r = 0.97)**
2. **over & runs_cumulative(r = 0.87)**
3. **wides & runs_extras(r = 0.76)**
5. **legbyes & runs_extras(r = 0.46)**
8. **byes & runs_extra(r = 0.38)**

Note that, using Pearson's r might not be able to capture non-linear relationships that potentially exist among these relationships.

```{python}
pd.DataFrame(train_data.groupby('powerplay')['wicket'].value_counts()).style.set_caption("Table 6: Wicket Count based off of Powerplay").set_table_styles([{
     'selector': 'caption',
     'props': 'caption-side: bottom; font-size:1.25em;'
 }], overwrite=False)
```

We can see that there is a much higher proportion of wickets during the powerplay (approximately 31% are wickets compared to only around 6% in non-powerplay conditions). This could be attributed to players taking more risks since there are more fielding restrictions in the powerplay (Bhattacharjee et al., 2016, pp. 39 - 47) While most of the game is in the powerplay, and there is a class imbalance, this suggests that the powerplay does affect the chances of a wicket.

```{python}
train_data.groupby('over')['wicket'].count().plot(kind = 'bar', xlabel="Over", ylabel="Wicket Count",
                                                   title = "Figure 3.1 : Wicket count across overs")
```

Similarly, the distribution above shows us that towards the end of the game, there are significantly less wickets than in the first few overs, which suggests that the variable "Over" could be used for our model as well.

```{python}
train_data.groupby('inning')['wicket'].count().plot(kind = 'bar', xlabel ='inning', ylabel = 'Wicket Count', 
                                                    title = "Figure 3.2: Wicket count across innings")
```

The above plot indicates that there are significantly more wickets in the first innings than the second. This could be attributed to the fact that in the second innings, batters are more likely to come in with a plan as they have a target in mind to chase and they are less likely to take risks. It is also possible that the number of wickets in the second innings is lower since the teams may not play the full second innings if they reach the target before that. So, this is a variable we will take into consideration when building our model.

```{python}
train_data_0 = train_data[train_data['wicket'] == 0]
train_data_1 = train_data[train_data['wicket'] == 1]

plt.hist(train_data_0['runs_cumulative'],  
         label="Not a Wicket",
         alpha = 0.5, 
         density = True) 
  
plt.hist(train_data_1['runs_cumulative'],  
         label="Wicket",
         alpha = 0.5,
         density=True) 
  
plt.legend(loc='upper right') 
plt.xlabel("Runs scored until Current Ball in Current Innings")
plt.ylabel("Probability Density")
plt.title('Figure 4: Wicket Probability Density by Cumulative runs scored in current innings') 
plt.show()
```

There does not seem to be too much of a relationship between the runs scored so far and whether there is a wicket or not, except when the runs are greater than 100. At this point, it is more likely to be a wicket.

### Model Building

Next, we will use the relationships we found above to build our model. The variables we will be looking at are `inning`, `over`, `powerplay`, `over_ball` and `runs_cumulative`. We will perform preprocessing on our datasets using one-hot encoding on our categorical variables. While there is only one numerical variable, we will still create a scaler in case we look to add other variables later in our analysis. 

We are going to create a Logistic Regression Model for this analysis. We decided against K-NN classification as there is class imbalance and even if we balance our classes by oversampling, our accuracy will decrease using a nearest neighbours methodology. We will be using a pipeline to fit our data.

```{python}
ohe = OneHotEncoder(drop = "if_binary", handle_unknown="ignore")
scaler = StandardScaler()

model = LogisticRegression(C = 10, class_weight="balanced", n_jobs=-1)


numerical_feats = ['runs_cumulative']
categorical_feats = ['inning', 'over', 'powerplay', 'over_ball',]
drop_feats = ['game_id', 'season', 'team','batter', 'batter_id', 'bowler',
       'bowler_id', 'non_striker', 'non_striker_id', 'wides', 'noballs',
       'legbyes', 'byes', 'player_out', 'player_out_id', 'fielders_name',
       'fielders_id', 'wicket_type', 'runs_batter', 'runs_extras', 
       'runs_total', 'team_over']


ct = make_column_transformer(
    (scaler, numerical_feats), 
    (ohe, categorical_feats),
    ("drop", drop_feats)
)
```

```{python}
pipe = make_pipeline(
    ct, 
    model
)
```

```{python}
pipe.fit(X_train, y_train)
```

#### Hyperparameter Optimization

The hyperparameter we are looking at in Logistic Regression is $C$. We will be testing for 5 different values of $C$ and looking at which gives us ideal cross-validation and training scores.

```{python}
C = [10 ** x for x in [0.5, 1, 2, 3, 4]]
train_score = []
cv_score = []
for c in C:
    model_new = LogisticRegression(C = c,  class_weight="balanced", n_jobs=-1)
    pipe_new = make_pipeline(ct, model_new)
    train_score.append(cross_validate(pipe_new, X_train, y_train, n_jobs =-1, return_train_score=True)['train_score'].mean())
    cv_score.append(cross_validate(pipe_new, X_train, y_train, n_jobs =-1, return_train_score=True)['test_score'].mean())

results = pd.DataFrame({"C": C, "Training Accuracy": train_score, "Cross Validation Accuracy": cv_score})
```

```{python}
results.style.set_caption("Table 7: Cross Validation and Training Accuracy after Hyperparameter Optimization").set_table_styles([{
     'selector': 'caption',
     'props': 'caption-side: bottom; font-size:1.25em;'
 }], overwrite=False)
```

We are choosing a $C$ of $\sqrt{10}$ as it overfits the least.

```{python}
final_model = LogisticRegression(C = 10**0.5, class_weight="balanced", n_jobs=-1)

final_pipe = make_pipeline(
    ct,
    final_model
)

final_pipe.fit(X_train, y_train)

final_pipe.score(X_test, y_test)
```

```{python}
conf_mat = metrics.confusion_matrix(y_test, final_pipe.predict(X_test))
plot_cm = metrics.ConfusionMatrixDisplay(conf_mat)
plot_cm.plot()
plt.title("Figure 5: Confusion Matrix")
plt.show()
```

# Discussion


## Summary of Results

1. Explorational Data Analysis: The exploration revealed several key insights that influence model building and interpretation. For example, the analysis shows the vast difference in player occurrences.
2. Model Building  and Selection: Based on the EDA findings, five features: Inning, over, powerplay, over_ball, and runs_cumulative were chosen based on the statistical relationships.One-hot encoding was applied for categorical variables to avoid introducing bias during model training.Finally, **Logistic Regression** was made due to the binary nature of the target variable (wicket or no wicket).Considering the potential drawbacks of class imbalance, the K-Nearest Neighbors (KNN) is not recommended.
3. Hyperparameter Optimization: Tuning the regularization parameter (C) of the Logistic Regression model to find the optimal balance between underfitting and overfitting. Testing various C values through cross-validation ensures the model generalizes well to unseen data.

## Unexpected Findings


- **Non-normality:** The extent of non-normality data across various features is unexpected. This highlights the importance of data exploration before model building.
- **Seasonal effect:** The temporal bias towards recent seasons might not be anticipated, requiring adjustments to ensure generalizability.


## Impact of Findings

These findings have several potential impacts:

- **Model development:** Understanding the distribution patterns and biases is crucial for choosing appropriate modeling techniques, interpreting outcomes, and guiding future data collection efforts.
- **Generalizability:** Addressing non-normality and temporal bias is essential for creating models that perform well on data beyond the training set.
- **Player analysis:** Exploring model results can unlock valuable insights into individual player performance and interaction with other factors influencing wicket probability.
- **Cricket analytics:** The model's insights can inform cricket analysts and fans about factors that influence wicket probabilities, leading to better predictions and understanding of the game.

## Future Questions and Work

These findings lead to several compelling questions for future research:

- **Addressing non-normality:** How can we effectively transform the data (e.g., log transformation)or utilize specific algorithms to improve model performance in the presence of *non-normal distributions*? 
- **Mitigating temporal bias:** What data augmentation techniques or alternative approaches can be used to ensure the model generalizes well across different time periods? Mitigating this bias are necessary for broader applicability.


And the future work includes:
- **Feature engineering:** Explore creating additional features or transformations of existing ones to capture more aspects of the game and potentially improve model performance.
- **Extra information:** Marshall et al. (2024) also discuss how pitch conditions could affect the possibility of a wicket. Having this data would help improve our model significantly.
- **Model performance evaluation:** Evaluate model perform on test data using appropriate classification performance metrics (e.g., F1-score, ROC AUC) and compare it with other potential models to identify the best approach for the task.


By addressing these questions, future research can build upon the current findings and develop even more robust and insightful models for predicting wicket probabilities in T20 cricket.


# References

Asif, M., & McHale, I. G. (2016). In-play forecasting of win probability in one-Day international cricket: A Dynamic Logistic Regression Model. International Journal of Forecasting, 32(1), 34–43. https://doi.org/10.1016/j.ijforecast.2015.02.005 

Bhattacharjee, D., Pandey, M., Saikia, H., & Radhakrishnan, U. K. (2016). Impact of Power Play Overs on the Outcome of Twenty20 Cricket Match. Annals of Applied Sports Science, 4(1), 39–47. https://doi.org/10.7508/aass.2016.01.007 

Dinsdale, D. (2023, December 5). Explaining next ball probability in cricket. The Analyst. https://theanalyst.com/na/2022/10/opta-next-ball-predictor/ 

Marshall, T., Runswick, O. R., & Broadbent, D. P. (2024). “what we talk about is creating a probability”: Exploring the interaction between the anticipation and decision-making processes of professional bowlers and batters in twenty20 cricket. Psychology of Sport and Exercise, 70, 102543. https://doi.org/10.1016/j.psychsport.2023.102543 


